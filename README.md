# Project introduction
This is the homework 6 project for Stat 154 at UC Berkeley.
In this study, we employed two distinct machine learning approaches to accomplish a text classification task: the detection of AI-generated essays. Our findings reveal that the RNN-based LSTM method outperforms the traditional machine learning approach, XG Boost, in training efficacy. We achieved a notable test accuracy of 99.04\% and an AUC of 0.9986 with a LSTM model and test accuracy of 92.46\% and an AUC of 0.9767 with an XG Boost model on a newly released and challenging dataset comprising texts generated by various state-of-the-art large language models.

# Dataset
To run the code, one needs to download the Daigt dataset, which is a publicly accessible resource available at https://www.kaggle.com/datasets/thedrcat/daigt-v2-train-dataset. This dataset serves the purpose of facilitating the identification of AI-generated essays. It encompasses a substantial collection of 27,371 essays composed by students, alongside an additional 17,497 essays generated by a diverse set of Large Language Models, including llama2\_chat, GPT4, Google Palm, and others. 

# Model Performance
| Model    | # Parameter | Accuracy (val) | Accuracy (test) | AUC (val) | AUC (test) |
|----------|-------------|----------------|-----------------|-----------|------------|
| LSTM     | 1,474,421   | 0.9834         | 0.9904          | 0.9984    | 0.9986     |
| XG Boost | 63,000      | 0.9170         | 0.9246          | 0.9716    | 0.9767     |
